{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ae6fd-d136-43b8-a46c-425facbd5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "abt_df = pd.read_csv('ABT_csv')\n",
    "\n",
    "continuous_features = ['dep_delay', 'arr_delay', 'temp', 'dewp', 'humid', 'wind_dir', 'wind_speed']\n",
    "\n",
    "# Plot histograms for continuous features\n",
    "for feature in continuous_features:\n",
    "    # Calculate Scott's bin width\n",
    "    n = len(abt_df[feature])\n",
    "    bin_width = 3.5 * abt_df[feature].std() / np.power(n, 1/3)\n",
    "    # Calculate the number of bins\n",
    "    num_bins = int((abt_df[feature].max() - abt_df[feature].min()) / bin_width)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(abt_df[feature], bins=num_bins, color='darkblue', edgecolor='black')\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for feature in continous_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(data=abt_df[continuous_feature], shade=True)\n",
    "    plt.title(f'Density Plot of {continuous_feature}')\n",
    "    plt.xlabel(continuous_feature)\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f997b90-3427-4a43-9865-40e50f41d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Analytic Base Table (ABT) into a DataFrame\n",
    "abt_df = pd.read_csv('ABT_csv')\n",
    "\n",
    "# Continuous Features\n",
    "continuous_features = ['dep_delay', 'arr_delay', 'temp', 'dewp', 'humid', 'wind_dir', 'wind_speed']\n",
    "\n",
    "# Calculate descriptive statistics for continuous features\n",
    "continuous_stats = abt_df[continuous_features].describe().transpose()\n",
    "\n",
    "# Calculate count of missing values for each continuous feature\n",
    "missing_values_count = abt_df[continuous_features].isnull().sum()\n",
    "\n",
    "# Calculate proportion of missing values for each continuous feature\n",
    "missing_values_percentage = (missing_values_count / len(abt_df)) * 100\n",
    "\n",
    "# Calculate cardinality for each continuous feature\n",
    "cardinality = abt_df[continuous_features].nunique()\n",
    "\n",
    "# Plot histograms for continuous features\n",
    "for feature in continuous_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(abt_df[feature], bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create DataFrame for continuous features\n",
    "continuous_data_quality_report = pd.DataFrame({\n",
    "    'Feature': continuous_stats.index,\n",
    "    'Minimum': continuous_stats['min'],\n",
    "    '1st Quartile': continuous_stats['25%'],\n",
    "    'Mean': continuous_stats['mean'],\n",
    "    'Median': continuous_stats['50%'],\n",
    "    '3rd Quartile': continuous_stats['75%'],\n",
    "    'Maximum': continuous_stats['max'],\n",
    "    'Standard Deviation': continuous_stats['std'],\n",
    "    'Total Instances': len(abt_df),\n",
    "    'Missing Values Count': missing_values_count,\n",
    "    'Missing Values Percentage': missing_values_percentage,\n",
    "    'Cardinality': cardinality\n",
    "})\n",
    "\n",
    "print(\"Continuous Data Quality Report:\")\n",
    "print(continuous_data_quality_report)\n",
    "\n",
    "# Categorical Features\n",
    "categorical_features = ['dest', 'origin', 'carrier']\n",
    "\n",
    "# Calculate mode and 2nd mode for each categorical feature\n",
    "mode_values = abt_df[categorical_features].mode()\n",
    "mode_counts = abt_df[categorical_features].apply(lambda x: x.value_counts().nlargest(2))\n",
    "\n",
    "# Calculate percentage of missing values for each categorical feature\n",
    "missing_values_percentage_cat = (abt_df[categorical_features].isnull().sum() / len(abt_df)) * 100\n",
    "\n",
    "# Calculate cardinality for each categorical feature\n",
    "cardinality_cat = abt_df[categorical_features].nunique()\n",
    "\n",
    "# Plot bar plots for categorical features\n",
    "for feature in categorical_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    abt_df[feature].value_counts().plot(kind='bar', color='skyblue')\n",
    "    plt.title(f'Bar plot of {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create DataFrame for categorical features\n",
    "categorical_data_quality_report = pd.DataFrame({\n",
    "    'Feature': mode_values.index,\n",
    "    'Mode': mode_values.iloc[:, 0],\n",
    "    'Mode Frequency': mode_counts.apply(lambda x: x[0] if len(x) > 0 else None),\n",
    "    '2nd Mode': mode_values.apply(lambda x: x[1] if len(x) > 1 else None),\n",
    "    '2nd Mode Frequency': mode_counts.apply(lambda x: x[1] if len(x) > 1 else None),\n",
    "    'Missing Values Percentage': missing_values_percentage_cat[mode_values.index],\n",
    "    'Cardinality': cardinality_cat[mode_values.index]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nCategorical Data Quality Report:\")\n",
    "print(categorical_data_quality_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444fa50-6a7c-422d-9909-175a49d5694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Analytic Base Table (ABT) into a DataFrame\n",
    "abt_df = pd.read_csv('ABT_csv')\n",
    "\n",
    "# Categorical Features\n",
    "categorical_features = ['dest', 'origin', 'carrier']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    # Calculate mode for the feature\n",
    "    mode_value = abt_df[feature].mode()[0]\n",
    "    \n",
    "    # Calculate frequency of mode value\n",
    "    mode_frequency = abt_df[feature].value_counts().max()\n",
    "    \n",
    "    # Calculate mode percentage\n",
    "    mode_percentage = (mode_frequency / len(abt_df)) * 100\n",
    "    \n",
    "    # Calculate second mode value and frequency\n",
    "    second_mode_value = abt_df[feature].value_counts().index[1] if len(abt_df[feature].value_counts()) > 1 else None\n",
    "    second_mode_frequency = abt_df[feature].value_counts().iloc[1] if len(abt_df[feature].value_counts()) > 1 else None\n",
    "    \n",
    "    # Calculate second mode percentage\n",
    "    second_mode_percentage = (second_mode_frequency / len(abt_df)) * 100 if second_mode_frequency else None\n",
    "    \n",
    "    # Calculate percentage of missing values\n",
    "    missing_values_percentage = (abt_df[feature].isnull().sum() / len(abt_df)) * 100\n",
    "    \n",
    "    # Calculate cardinality\n",
    "    cardinality = abt_df[feature].nunique()\n",
    "    \n",
    "    # Calculate total count\n",
    "    total_count = len(abt_df)\n",
    "    \n",
    "    print(f\"\\nCategorical Data Quality Report for {feature}:\")\n",
    "    print(f\"Mode: {mode_value}\")\n",
    "    print(f\"Mode Frequency: {mode_frequency}\")\n",
    "    print(f\"Mode Percentage: {mode_percentage}%\")\n",
    "    print(f\"Second Mode: {second_mode_value}\")\n",
    "    print(f\"Second Mode Frequency: {second_mode_frequency}\")\n",
    "    print(f\"Second Mode Percentage: {second_mode_percentage}%\")\n",
    "    print(f\"Missing Values Percentage: {missing_values_percentage}%\")\n",
    "    print(f\"Cardinality: {cardinality}\")\n",
    "    print(f\"Total Count: {total_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0a60e-0b8d-43c5-aebb-1fe53f93333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "abt_df = pd.read_csv('ABT_csv')\n",
    "\n",
    "print(abt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193c56f-81f9-4725-b4c1-b562fea04d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABT\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "flights_df = pd.read_csv('CasusEDA/csv/flights_csv')\n",
    "weather_df = pd.read_csv('CasusEDA/csv/weather_csv')\n",
    "\n",
    "flights_selected = flights_df[['dest', 'origin', 'carrier', 'dep_delay', 'arr_delay', 'time_hour']]\n",
    "weather_selected = weather_df[['origin', 'temp', 'dewp', 'humid', 'wind_dir', 'wind_speed', 'time_hour']]\n",
    "\n",
    "merged_df = flights_selected.merge(weather_selected, how='left', on=['time_hour', 'origin'])\n",
    "\n",
    "print(merged_df)\n",
    "merged_df.to_csv('ABT_csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c4e26-594f-4662-92ac-4fb2cc06b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airlines = pd.read_csv('CasusEDA/csv/airlines_csv')\n",
    "flights = pd.read_csv('CasusEDA/csv/flights_csv')\n",
    "\n",
    "df = pd.merge(airlines,flights,on='carrier')\n",
    "df1 = df.where(flights['carrier'] =='AA')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dcdb8-d5e6-453b-a909-85537b0e98a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather = pd.read_csv('CasusEDA/csv/weather_csv')\n",
    "\n",
    "weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfdb9c-7b4f-4270-a24d-c89f1b7bea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airports = pd.read_csv('CasusEDA/csv/airports_csv')\n",
    "\n",
    "airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d36c95-d753-4567-8cc6-05c5960e04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "flights = pd.read_csv('CasusEDA/csv/flights_csv')\n",
    "\n",
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb1610-3ad9-40dc-aac1-d47692938d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "planes = pd.read_csv('CasusEDA/csv/planes_csv')\n",
    "\n",
    "planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256e93b-2347-41ed-8b90-779fcd15dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airlines = pd.read_csv('CasusEDA/csv/airlines_csv')\n",
    "\n",
    "airlines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
